{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40Yb47zJQglm"
   },
   "source": [
    "# **Deep Reinforcement Learning**\n",
    "\n",
    "# M3-2 Deep Q-Networks\n",
    "\n",
    "## Example of DQN implementation on Pong environment (Part 2, testing)\n",
    "\n",
    "Below we will see a simple example that will allow us to understand the concepts introduced in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pong environment\n",
    "\n",
    "The [Pong](https://gymnasium.farama.org/environments/atari/pong/) environment is part of the [Atari environments](https://gymnasium.farama.org/environments/atari/). Please read that page first for general information.\n",
    "\n",
    "You control the right paddle, you compete against the left paddle controlled by the computer. You each try to keep deflecting the ball away from your goal and into your opponent’s goal.\n",
    "\n",
    "<center><img src=\"https://ale.farama.org/_images/pong.gif\"/></center>\n",
    "\n",
    "For a more detailed documentation, see the [AtariAge page](https://atariage.com/manual_html_page.php?SoftwareLabelID=587)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maCHXYw1G8Km"
   },
   "source": [
    "First of all, we will load the environment. It is important to note that in this case, we will load the \"preliminary\" version of the environment, which belongs to the [Gym](https://github.com/openai/gym) framework (instead of [Gymnasium](https://gymnasium.farama.org/index.html)).\n",
    "\n",
    "To install this environment, we need to execute the following command:\n",
    "> pip install gym==0.25.0\n",
    "\n",
    "And all related packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-24T12:29:07.276035Z",
     "iopub.status.busy": "2024-10-24T12:29:07.275616Z",
     "iopub.status.idle": "2024-10-24T12:30:15.286272Z",
     "shell.execute_reply": "2024-10-24T12:30:15.284876Z",
     "shell.execute_reply.started": "2024-10-24T12:29:07.275994Z"
    },
    "id": "0QIIk_u6f0MT",
    "outputId": "761efe8d-8987-4bbb-f192-cb13cb95b609",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.25.0 (from gym[atari]==0.25.0)\n",
      "  Downloading gym-0.25.0.tar.gz (720 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.0->gym[atari]==0.25.0) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.0->gym[atari]==0.25.0) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.0->gym[atari]==0.25.0) (0.0.8)\n",
      "Collecting ale-py~=0.7.5 (from gym[atari]==0.25.0)\n",
      "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.7.5->gym[atari]==0.25.0) (6.4.0)\n",
      "Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.25.0-py3-none-any.whl size=824405 sha256=4fe89f8b6b958aaba632ecd0c049eb53ba19e0c50eb6c0ceb0c1bf6d130231d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/3c/33/32d86254a5bd554f5f07759ae1794646e490dd5fa81ebdcda3\n",
      "Successfully built gym\n",
      "Installing collected packages: gym, ale-py\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed ale-py-0.7.5 gym-0.25.0\n",
      "Collecting autorom[accept-rom-license]\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (2.32.3)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (2024.8.30)\n",
      "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=b95da3cd4bab6639f045170ce3e902a0c411b5a65e97502c33e1bc2713c84c13\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[atari]==0.25.0\n",
    "!pip install autorom[accept-rom-license]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dependencies are installed, we load them and initialize the `PongNoFrameskip-v4` environment.\n",
    "\n",
    "There are several Pong environments, with minor differences among them. See [Pong](https://gymnasium.farama.org/environments/atari/pong/) page for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:15.289347Z",
     "iopub.status.busy": "2024-10-24T12:30:15.288890Z",
     "iopub.status.idle": "2024-10-24T12:30:16.380794Z",
     "shell.execute_reply": "2024-10-24T12:30:16.379271Z",
     "shell.execute_reply.started": "2024-10-24T12:30:15.289299Z"
    },
    "id": "FA1Y5VCv20XZ",
    "outputId": "35a6fbb0-5d3e-4941-e0c3-1f1a6674b0bf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Gym version 0.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# version\n",
    "print(\"Using Gym version {}\".format(gym.__version__))\n",
    "\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "test_env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnXgUWhMf0MV"
   },
   "source": [
    "### Data preprocessing (Wrappers)\n",
    "\n",
    "We need to apply the **same set of wrappers** used during the model's training phase to ensure that the inputs to the model are consistent in shape, format, and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:16.383679Z",
     "iopub.status.busy": "2024-10-24T12:30:16.383156Z",
     "iopub.status.idle": "2024-10-24T12:30:16.421687Z",
     "shell.execute_reply": "2024-10-24T12:30:16.420448Z",
     "shell.execute_reply.started": "2024-10-24T12:30:16.383619Z"
    },
    "id": "nPi1lHINMuSu"
   },
   "outputs": [],
   "source": [
    "# OpenAI Gym Wrappers\n",
    "# Taken from\n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/wrappers.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "import gym.spaces\n",
    "\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        return obs\n",
    "\n",
    "    \n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1],\n",
    "                                old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "    \n",
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    print(\"Standard Env.        : {}\".format(env.observation_space.shape))\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    print(\"MaxAndSkipEnv        : {}\".format(env.observation_space.shape))\n",
    "    env = FireResetEnv(env)\n",
    "    print(\"FireResetEnv         : {}\".format(env.observation_space.shape))\n",
    "    env = ProcessFrame84(env)\n",
    "    print(\"ProcessFrame84       : {}\".format(env.observation_space.shape))\n",
    "    env = ImageToPyTorch(env)\n",
    "    print(\"ImageToPyTorch       : {}\".format(env.observation_space.shape))\n",
    "    env = BufferWrapper(env, 4)\n",
    "    print(\"BufferWrapper        : {}\".format(env.observation_space.shape))\n",
    "    env = ScaledFloatFrame(env)\n",
    "    print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "    \n",
    "    return env\n",
    "\n",
    "\n",
    "def print_env_info(name, env):\n",
    "    obs = env.reset()\n",
    "    print(\"*** {} Environment ***\".format(name))\n",
    "    print(\"Observation shape: {}, type: {} and range [{},{}]\".format(obs.shape, obs.dtype, np.min(obs), np.max(obs)))\n",
    "    print(\"Observation sample:\\n{}\".format(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:16.424947Z",
     "iopub.status.busy": "2024-10-24T12:30:16.424488Z",
     "iopub.status.idle": "2024-10-24T12:30:16.696613Z",
     "shell.execute_reply": "2024-10-24T12:30:16.695254Z",
     "shell.execute_reply.started": "2024-10-24T12:30:16.424892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Env.        : (210, 160, 3)\n",
      "MaxAndSkipEnv        : (210, 160, 3)\n",
      "FireResetEnv         : (210, 160, 3)\n",
      "ProcessFrame84       : (84, 84, 1)\n",
      "ImageToPyTorch       : (1, 84, 84)\n",
      "BufferWrapper        : (4, 84, 84)\n",
      "ScaledFloatFrame     : (4, 84, 84)\n",
      "*** Wrapped Environment ***\n",
      "Observation shape: (4, 84, 84), type: float32 and range [0.0,0.6352941393852234]\n",
      "Observation sample:\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.34117648 0.34117648 0.34117648 ... 0.34117648 0.34117648 0.34117648]\n",
      "  [0.34117648 0.34117648 0.34117648 ... 0.34117648 0.34117648 0.34117648]\n",
      "  [0.34117648 0.34117648 0.34117648 ... 0.34117648 0.34117648 0.34117648]\n",
      "  ...\n",
      "  [0.34117648 0.34117648 0.34117648 ... 0.34117648 0.34117648 0.34117648]\n",
      "  [0.34117648 0.34117648 0.34117648 ... 0.34117648 0.34117648 0.34117648]\n",
      "  [0.56078434 0.56078434 0.56078434 ... 0.56078434 0.56078434 0.56078434]]]\n"
     ]
    }
   ],
   "source": [
    "# wrapped Env\n",
    "env = make_env(ENV_NAME)\n",
    "print_env_info(\"Wrapped\", env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NN5Ps-fUHHeG"
   },
   "source": [
    "### Neural network architecture\n",
    "\n",
    "The following code will implement the NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:16.698658Z",
     "iopub.status.busy": "2024-10-24T12:30:16.698156Z",
     "iopub.status.idle": "2024-10-24T12:30:20.480300Z",
     "shell.execute_reply": "2024-10-24T12:30:20.478883Z",
     "shell.execute_reply.started": "2024-10-24T12:30:16.698611Z"
    },
    "id": "h6B8v-Qh5Ykk",
    "outputId": "f75efde2-e5a9-43ce-f3d7-98257ac93051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:20.482258Z",
     "iopub.status.busy": "2024-10-24T12:30:20.481724Z",
     "iopub.status.idle": "2024-10-24T12:30:20.490087Z",
     "shell.execute_reply": "2024-10-24T12:30:20.488871Z",
     "shell.execute_reply.started": "2024-10-24T12:30:20.482216Z"
    },
    "id": "IvZMDEFBXAMC"
   },
   "outputs": [],
   "source": [
    "def make_DQN(input_shape, output_shape):\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64*7*7, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, output_shape)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p0jvxoC3m5W"
   },
   "source": [
    "### Test\n",
    "\n",
    "We play several episodes and save them (.gif or .mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-24T12:30:20.492672Z",
     "iopub.status.busy": "2024-10-24T12:30:20.492037Z",
     "iopub.status.idle": "2024-10-24T12:30:43.199377Z",
     "shell.execute_reply": "2024-10-24T12:30:43.198041Z",
     "shell.execute_reply.started": "2024-10-24T12:30:20.492612Z"
    },
    "id": "BvN4S8R53mJI",
    "outputId": "0cea21eb-9cca-4ed5-821a-97e3e53b11c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Env.        : (210, 160, 3)\n",
      "MaxAndSkipEnv        : (210, 160, 3)\n",
      "FireResetEnv         : (210, 160, 3)\n",
      "ProcessFrame84       : (84, 84, 1)\n",
      "ImageToPyTorch       : (1, 84, 84)\n",
      "BufferWrapper        : (4, 84, 84)\n",
      "ScaledFloatFrame     : (4, 84, 84)\n",
      "Total reward: 18.00\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "model = \"/kaggle/input/pongnoframeskip-v4/pytorch/dqn/1/PongNoFrameskip-v4.dat\"\n",
    "visualize = True\n",
    "images = []\n",
    "\n",
    "env = make_env(ENV_NAME)\n",
    "net = make_DQN(env.observation_space.shape, env.action_space.n)\n",
    "net.load_state_dict(torch.load(model, map_location=torch.device(device)))\n",
    "\n",
    "state = env.reset()\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    start_ts = time.time()\n",
    "    if visualize:\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(Image.fromarray(img))\n",
    "\n",
    "    state_ = torch.tensor(np.array([state], copy=False))\n",
    "    q_vals = net(state_).data.numpy()[0]\n",
    "    action = np.argmax(q_vals)\n",
    "\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Total reward: %.2f\" % total_reward)\n",
    "\n",
    "# duration is the number of milliseconds between frames; this is 40 frames per second\n",
    "images[0].save(\"video.gif\", save_all=True, append_images=images[1:], duration=60, loop=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 143636,
     "modelInstanceId": 120421,
     "sourceId": 142152,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
