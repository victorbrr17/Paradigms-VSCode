Iteration 0: loss=0.683, reward_mean=24.5, reward_bound=28.5
Iteration 1: loss=0.665, reward_mean=26.7, reward_bound=27.0
Iteration 2: loss=0.654, reward_mean=27.0, reward_bound=33.5
Iteration 3: loss=0.634, reward_mean=32.8, reward_bound=42.0
Iteration 4: loss=0.625, reward_mean=43.7, reward_bound=48.5
Iteration 5: loss=0.618, reward_mean=45.6, reward_bound=48.0
Iteration 6: loss=0.589, reward_mean=42.8, reward_bound=48.0
Iteration 7: loss=0.599, reward_mean=66.4, reward_bound=86.5
Iteration 8: loss=0.603, reward_mean=40.2, reward_bound=49.5
Iteration 9: loss=0.606, reward_mean=60.8, reward_bound=73.0
Iteration 10: loss=0.570, reward_mean=56.0, reward_bound=60.0
Iteration 11: loss=0.562, reward_mean=59.1, reward_bound=69.0
Iteration 12: loss=0.563, reward_mean=65.6, reward_bound=71.5
Iteration 13: loss=0.556, reward_mean=65.3, reward_bound=71.5
Iteration 14: loss=0.548, reward_mean=66.6, reward_bound=91.0
Iteration 15: loss=0.533, reward_mean=52.2, reward_bound=63.0
Iteration 16: loss=0.525, reward_mean=59.9, reward_bound=80.5
Iteration 17: loss=0.529, reward_mean=61.2, reward_bound=71.5
Iteration 18: loss=0.541, reward_mean=67.2, reward_bound=66.0
Iteration 19: loss=0.532, reward_mean=66.1, reward_bound=70.0
Iteration 20: loss=0.509, reward_mean=64.4, reward_bound=72.5
Iteration 21: loss=0.507, reward_mean=71.2, reward_bound=77.5
Iteration 22: loss=0.484, reward_mean=105.1, reward_bound=105.0
Iteration 23: loss=0.510, reward_mean=88.4, reward_bound=90.0
Iteration 24: loss=0.518, reward_mean=69.1, reward_bound=74.0
Iteration 25: loss=0.504, reward_mean=83.8, reward_bound=102.5
Iteration 26: loss=0.524, reward_mean=81.8, reward_bound=88.0
Iteration 27: loss=0.499, reward_mean=90.0, reward_bound=83.0
Iteration 28: loss=0.475, reward_mean=111.2, reward_bound=110.5
Iteration 29: loss=0.502, reward_mean=122.8, reward_bound=125.5
Iteration 30: loss=0.493, reward_mean=132.0, reward_bound=150.0
Iteration 31: loss=0.497, reward_mean=119.6, reward_bound=133.0
Iteration 32: loss=0.484, reward_mean=147.1, reward_bound=181.5
Iteration 33: loss=0.484, reward_mean=154.3, reward_bound=162.5
Iteration 34: loss=0.484, reward_mean=167.6, reward_bound=187.5
Iteration 35: loss=0.480, reward_mean=170.2, reward_bound=184.0
Iteration 36: loss=0.509, reward_mean=177.0, reward_bound=188.0
Iteration 37: loss=0.492, reward_mean=251.7, reward_bound=278.5
Solved!
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
